{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <title>{{ experience.title }} ‚Äì Python AR Experience</title>
  
  <style>
    /* Your existing styles... */
    
    /* Camera Stream Styles */
    .camera-container {
      position: fixed;
      inset: 0;
      width: 100vw;
      height: 100vh;
      background: #000;
      z-index: 1;
    }
    
    #cameraVideo {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    
    #processingCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    
    .camera-controls {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 1001;
      display: flex;
      gap: 10px;
    }
  </style>
</head>
<body>
  <!-- Your existing UI elements... -->
  
  <!-- Camera Container -->
  <div id="camera-container" class="camera-container">
    <video id="cameraVideo" autoplay muted playsinline></video>
    <canvas id="processingCanvas"></canvas>
  </div>
  
  <!-- Camera Controls -->
  <div class="camera-controls">
    <button id="startCamera" class="btn">üìπ Start Camera</button>
    <button id="stopCamera" class="btn" style="display:none;">‚èπÔ∏è Stop Camera</button>
    <button id="switchCamera" class="btn">üîÑ Switch</button>
  </div>
  
  <!-- Configuration Script -->
  <script>
    window.AR_CONFIG = {
        slug: '{{ experience.slug }}',
        pythonArReady: {{ python_ar_ready|yesno:"true,false" }},
        overlaySettings: {
            scale: {{ experience.overlay_scale|default:1.0 }},
            opacity: {{ experience.overlay_opacity|default:0.8 }},
            sensitivity: {{ experience.detection_sensitivity|default:0.7 }}
        },
        processingMethod: '{{ experience.processing_method|default:"python_webrtc" }}',
        featureCount: {{ experience.feature_count|default:0 }},
        trackingQuality: {{ experience.tracking_quality|default:0.0 }}
    };
  </script>
  
  <!-- WebRTC AR Script -->
  <script>
    // WebRTC Camera + Python AR Processing
    class WebRTCPythonAR {
        constructor() {
            this.video = null;
            this.canvas = null;
            this.ctx = null;
            this.stream = null;
            this.isProcessing = false;
            this.frameCount = 0;
        }
        
        async init() {
            this.video = document.getElementById('cameraVideo');
            this.canvas = document.getElementById('processingCanvas');
            this.ctx = this.canvas.getContext('2d');
            
            // Set canvas size to match video
            this.canvas.width = 640;
            this.canvas.height = 480;
        }
        
        async startCamera() {
            try {
                console.log('üé• Starting WebRTC camera...');
                
                this.stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        width: { ideal: 640 },
                        height: { ideal: 480 },
                        facingMode: 'environment' // Back camera on mobile
                    },
                    audio: false
                });
                
                this.video.srcObject = this.stream;
                await this.video.play();
                
                console.log('‚úÖ Camera started successfully');
                this.startProcessing();
                
                // Update UI
                document.getElementById('startCamera').style.display = 'none';
                document.getElementById('stopCamera').style.display = 'inline-block';
                
                // Update status
                this.updateStatus('stream', 'Active', 'active');
                
            } catch (error) {
                console.error('‚ùå Camera access failed:', error);
                alert('Camera access failed: ' + error.message);
            }
        }
        
        stopCamera() {
            if (this.stream) {
                this.stream.getTracks().forEach(track => track.stop());
                this.stream = null;
            }
            
            this.isProcessing = false;
            this.video.srcObject = null;
            
            // Update UI
            document.getElementById('startCamera').style.display = 'inline-block';
            document.getElementById('stopCamera').style.display = 'none';
            
            // Update status
            this.updateStatus('stream', 'Stopped', 'ready');
            
            console.log('‚èπÔ∏è Camera stopped');
        }
        
        startProcessing() {
            this.isProcessing = true;
            this.processFrame();
        }
        
        processFrame() {
            if (!this.isProcessing) return;
            
            try {
                // Draw video frame to canvas
                this.ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);
                
                // Add Python AR overlay
                this.addAROverlay();
                
                // Send frame to Django for processing (optional)
                if (this.frameCount % 10 === 0) { // Every 10th frame
                    this.sendFrameToServer();
                }
                
                this.frameCount++;
                
            } catch (error) {
                console.error('Frame processing error:', error);
            }
            
            // Continue processing
            requestAnimationFrame(() => this.processFrame());
        }
        
        addAROverlay() {
            // Add Python AR processing indicators
            this.ctx.fillStyle = 'rgba(0, 255, 0, 0.8)';
            this.ctx.font = '16px monospace';
            
            // AR Status
            this.ctx.fillText(`üêç Python AR: ${window.AR_CONFIG.slug}`, 10, 30);
            this.ctx.fillText(`Frame: ${this.frameCount}`, 10, 50);
            this.ctx.fillText(`Method: ${window.AR_CONFIG.processingMethod}`, 10, 70);
            this.ctx.fillText(`Quality: ${window.AR_CONFIG.trackingQuality}`, 10, 90);
            
            // Marker detection placeholder
            if (this.frameCount % 60 < 30) { // Blink every 2 seconds
                this.ctx.strokeStyle = 'lime';
                this.ctx.lineWidth = 3;
                this.ctx.strokeRect(200, 150, 200, 150);
                this.ctx.fillText('üéØ Marker Area', 210, 140);
            }
            
            // Video overlay simulation
            if (window.AR_CONFIG.pythonArReady) {
                this.ctx.fillStyle = 'rgba(255, 255, 0, 0.6)';
                this.ctx.fillRect(250, 200, 100, 60);
                this.ctx.fillStyle = 'black';
                this.ctx.fillText('üìπ Video', 260, 235);
            }
        }
        
        async sendFrameToServer() {
            try {
                // Get image data from canvas
                const imageData = this.canvas.toDataURL('image/jpeg', 0.7);
                
                // Send to Django API for processing
                const response = await fetch(`/api/process-ar-frame/${window.AR_CONFIG.slug}/`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]')?.value || ''
                    },
                    body: JSON.stringify({
                        frame: imageData,
                        frame_count: this.frameCount
                    })
                });
                
                if (response.ok) {
                    const result = await response.json();
                    // Handle AR processing result
                    console.log('AR processing result:', result);
                }
                
            } catch (error) {
                console.error('Server processing error:', error);
            }
        }
        
        updateStatus(kind, label, cls) {
            const dot = document.getElementById(kind + "-dot");
            const txt = document.getElementById(kind + "-status");
            if (dot) dot.className = "dot " + (cls || "");
            if (txt) txt.textContent = label;
        }
        
        async switchCamera() {
            if (this.stream) {
                const videoTrack = this.stream.getVideoTracks()[0];
                const currentFacingMode = videoTrack.getSettings().facingMode;
                
                this.stopCamera();
                
                // Switch between front and back camera
                const newFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
                
                setTimeout(async () => {
                    try {
                        this.stream = await navigator.mediaDevices.getUserMedia({
                            video: { 
                                width: { ideal: 640 },
                                height: { ideal: 480 },
                                facingMode: newFacingMode
                            },
                            audio: false
                        });
                        
                        this.video.srcObject = this.stream;
                        await this.video.play();
                        this.startProcessing();
                        
                        document.getElementById('startCamera').style.display = 'none';
                        document.getElementById('stopCamera').style.display = 'inline-block';
                        
                    } catch (error) {
                        console.error('Camera switch failed:', error);
                        alert('Camera switch failed: ' + error.message);
                    }
                }, 500);
            }
        }
    }
    
    // Initialize AR system
    const pythonAR = new WebRTCPythonAR();
    
    document.addEventListener('DOMContentLoaded', async () => {
        await pythonAR.init();
        
        // Button event listeners
        document.getElementById('startCamera').onclick = () => pythonAR.startCamera();
        document.getElementById('stopCamera').onclick = () => pythonAR.stopCamera();
        document.getElementById('switchCamera').onclick = () => pythonAR.switchCamera();
        
        console.log('üéØ WebRTC Python AR system ready');
    });
    
    // Auto-start camera if supported
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        console.log('üì± WebRTC supported - ready for camera access');
    } else {
        console.error('‚ùå WebRTC not supported in this browser');
        alert('Your browser does not support camera access');
    }
  </script>
</body>
</html>
